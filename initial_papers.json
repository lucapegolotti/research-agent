[
    {
        "title": "Attention Is All You Need",
        "arxiv_id": "1706.03762"
    },
    {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "arxiv_id": "1810.04805"
    },
    {
        "title": "Language Models are Few-Shot Learners (GPT-3)",
        "arxiv_id": "2005.14165"
    },
    {
        "title": "Improving Language Understanding by Generative Pre-Training (GPT-1)",
        "pdf_url": "https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf",
        "file_prefix": "OpenAI_GPT1" 
    },
    {
        "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
        "arxiv_id": "2201.11903"
    },
    {
        "title": "Training language models to follow instructions with human feedback (InstructGPT)",
        "arxiv_id": "2203.02155"
    },
    {
        "title": "Constitutional AI: Harmlessness from AI Feedback",
        "arxiv_id": "2212.08073"
    },
    {
        "title": "LLaMA: Open and Efficient Foundation Language Models",
        "arxiv_id": "2302.13971"
    },
    {
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (RAG)",
        "arxiv_id": "2005.11401"
    },
    {
        "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
        "arxiv_id": "2112.11446"
    },
    {
        "title": "Palm: Scaling language modeling with pathways",
        "arxiv_id": "2204.02311"
    },
    {
        "title": "OPT: Open Pre-trained Transformer Language Models",
        "arxiv_id": "2205.01068"
    },
    {
        "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
        "arxiv_id": "2203.11171"
    },
    {
        "title": "A Survey of Large Language Models",
        "arxiv_id": "2303.18223"
    },
    {
        "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
        "arxiv_id": "2302.04761"
    },
    {
        "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
        "arxiv_id": "2303.12712"
    },
    {
        "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
        "arxiv_id": "2305.14314"
    },
    {
        "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model (DPO)",
        "arxiv_id": "2305.18290"
    },
    {
        "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "arxiv_id": "2104.08691"
    },
    {
        "title": "LLaMA 2: Open Foundation and Fine-Tuned Chat Models",
        "arxiv_id": "2307.09288"
    }
]